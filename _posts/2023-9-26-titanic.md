---
layout: post
title: "Titanic - Machine Learning from Disaster"
date: 2023-09-26
author: Juan Martin Maidana
categories: [Classification]
tags: [Data Cleaning, Data Visualization, Binary Classification]
image:
  path: /assets/img/favicons/Titanic/preview.jpg
  alt: Titanic Preview
---

# Titanic - Machine Learning from Disaster

The Titanic dataset presents an intriguing opportunity for data exploration, in this post we are going to dive into the preprocessing using Python. Our goal is to get hands-on with the Titanic dataset, understand its ins and outs, and make informed predictions about whether passengers survived or not. As we navigate through this dataset, we'll handle the data, create models, and unveil the intriguing tale of the Titanic.


# Metadata Dataset

- Survived – Survival (0 = No; 1 = Yes) 
- PassengerId – Identification number for each person 
- Pclass – Passenger Class (1 = 1st ;  2 = 2nd ; 3 = 3rd ) 
- Name – Passenger Name Sex – Sex (male of female) 
- SibSp – Number of Siblings/Spouses Aboard 
- Parch – Number of Parents/Children Aboard 
- Ticket – Ticket Number 
- Fare – Passenger Fare 
- Cabin – Passenger Cabin 
- Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)


# Input data

Firstly, we are going to import the two datasets, one for training called “train.csv” and other for testing called “test.csv”. This dataset has the advantage that already the data is divided in both separated csv.

```python
import numpy as np 
import pandas as pd 
import seaborn as sns

from matplotlib import pyplot as plt
sns.set_style("whitegrid")

import warnings
warnings.filterwarnings("ignore")

pd.read_csv("train.csv")
pd.read_csv("test.csv")
```


To check that both sets were loaded correctly, we are going to use the the .head() function to print the first lines of the training csv.

```python
print(training.head())
```

![TitanicHeadTraining](/assets/img/favicons/Titanic/headtitanic1.png)

![TitanicDescribe](/assets/img/favicons/Titanic/describe.png)

# Missing Values

Now the problem to attack are the missing values, as you can see, the datasets could be loaded correctly and even some useful analytical statistics were shown for the future. But now we will have to analyze what these values are, how important they are for the label and, of the most important things, what quantity they are.

As you can see, the column "Cabin" Bene many missing values, there are several ways to deal with these values, one of them is the imputation, using different methods to implement them, another method is to simply ignore the column, something that in some situations can be useful if there are too many missing values or it does not have much relevance in the objective variable.

![TitanicMissingValuesTest](/assets/img/favicons/Titanic/missingvalues.png)

On the other hand, the column "Age" has much less quantity and it is a vital column for the label variable, in this case the imputation can be applied. But in the case of "Cabin" it is better not to take it into account. Here we also get rid of “Ticket” because it’s not giving us any information useful for the model, it’s only a identification number for the entry.


```python
training.drop(labels = ["Cabin", "Ticket"], axis = 1, inplace = True)
testing.drop(labels = ["Cabin", "Ticket"], axis = 1, inplace = True)
```

We already know that there are not many missing values in the "Age" column, but to be more precise in deciding what kind of imputation to do, we first have to look at the ranges and distribution of the data in the column.

![TitanicAges](/assets/img/favicons/Titanic/egestitanic.png)


As you can see in the graph, the ages are a bit skewed to the right, so taking the mean may not be the best option, because as we know in these cases high values have a lot of weight in the mean. On the other hand, the median may be more accurate when replacing this missing values. Although it is known that it is not ideal to impute data, the median is the best option.

```python
training["Age"].fillna(training["Age"].median(), inplace = True)
testing["Age"].fillna(testing["Age"].median(), inplace = True) 
training["Embarked"].fillna("S", inplace = True)
testing["Fare"].fillna(testing["Fare"].median(), inplace = True)

null_table(training, testing)
```

![TitanicNullTable](/assets/img/favicons/Titanic/nulltable.png)


# Data Visualization


![TitanicGenre](/assets/img/favicons/Titanic/genre.png){: width="972" height="589" .w-50 .right}
It is important to analyze and visualize through graphs the data that we are going to use in our model, in this way we can find some important finding that can influence the model, for example, we can see how important are the attributes "Age" or "Sex" through which graphs. In other case perhaps it’s easier to use the correlative matrix to find this influence on the label, but here thanks to the understanding of the data I can know for sure that the age and sex of the person it’s very important for the label.
As we can see the "Sex" column is very striking in terms of the results, and based on this graph we can draw the conclusion that this attribute is vital in predicting the label.


```python
sns.barplot(x="Pclass", y="Survived", data=training)
plt.ylabel("Survival Rate")
plt.title("Distribution of Survival Based on Class")
plt.show()

total_survived_one = training[training.Pclass == 1]["Survived"].sum()
total_survived_two = training[training.Pclass == 2]["Survived"].sum()
total_survived_three = training[training.Pclass == 3]["Survived"].sum()
total_survived_class = total_survived_one + total_survived_two + total_survived_three
```



![TitanicClass](/assets/img/favicons/Titanic/pclass2.png){: width="972" height="589" .w-50 .left}
Similar to the previous concept, we can see how class is also a key attribute in predicting whether or not you survived, since the large number of people who lived were in class number "1", with a survival rate of just over 0.6.


![TitanicTotal](/assets/img/favicons/Titanic/total2.png){: width="1172" height="889" .w-75}


















<!-- > Hi!!! How are you
{: .prompt-tip }

```
This is a common code snippet, without syntax highlight and line number.+


x
``` -->





